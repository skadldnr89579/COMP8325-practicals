{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# encoding=utf8\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"capture20110816-3.binetflow\")\n",
    "data['Label'] = data.Label.str.contains(\"Botnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartTime', 'Dur', 'Proto', 'SrcAddr', 'Sport', 'Dir', 'DstAddr',\n",
       "       'Dport', 'State', 'sTos', 'dTos', 'TotPkts', 'TotBytes', 'SrcBytes',\n",
       "       'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LoadData\n",
    "import DataPreparation\n",
    "import pickle, codecs\n",
    "\n",
    "file = codecs.open('flowdata.pickle', 'rb')\n",
    "data  = pickle.load(file, encoding=\"latin1\")\n",
    "#file = codecs.open('CTU13Scenario1flowData.pickle', 'rb')\n",
    "#botnet_dataset = pickle.load(file, encoding=\"latin1\")\n",
    "#botnet_dataset = pickle.load(file, encoding=\"bytes\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[9.8398800e-01, 0.0000000e+00, 4.5190000e+03, ..., 4.0000000e+00,\n",
       "         2.4400000e+02, 6.1105000e+04],\n",
       "        [9.0989500e-01, 0.0000000e+00, 6.1591000e+04, ..., 3.0000000e+00,\n",
       "         2.0400000e+02, 3.4000000e+01],\n",
       "        [3.0674230e+00, 0.0000000e+00, 2.2280000e+03, ..., 3.0000000e+00,\n",
       "         1.8400000e+02, 3.1190000e+03],\n",
       "        ...,\n",
       "        [6.0939800e+01, 0.0000000e+00, 3.9280000e+03, ..., 1.0000000e+01,\n",
       "         1.0760000e+03, 2.1634100e+05],\n",
       "        [6.0939594e+01, 0.0000000e+00, 3.9290000e+03, ..., 1.0000000e+01,\n",
       "         1.0760000e+03, 2.1634100e+05],\n",
       "        [7.9903100e-01, 0.0000000e+00, 3.9300000e+03, ..., 6.0000000e+00,\n",
       "         8.3600000e+02, 2.9890000e+03]]),\n",
       " array([0, 0, 0, ..., 1, 1, 1]),\n",
       " array([], dtype=float64),\n",
       " array([], dtype=float64)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata = data[0]\n",
    "Ydata =  data[1]\n",
    "XdataT = data[2]\n",
    "YdataT = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata, test_size=0.2, random_state=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Prepare(Thread-4, initial)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataPreparation.Prepare(Xdata,Ydata,XdataT,YdataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score of the Decision Tree Classifier is 99.78951396861845\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "Prediction = clf.predict(X_test)\n",
    "Score = clf.score(X_test,y_test)\n",
    "print (\"The Score of the Decision Tree Classifier is\", Score * 100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score of the Decision Tree Classifier is 99.78951396861845\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "prediction=dt.predict(X_test)\n",
    "score=dt.score(X_test,y_test)\n",
    "print (\"The Score of the Decision Tree Classifier is\", Score * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3966\n",
      "           1       1.00      1.00      1.00      1260\n",
      "\n",
      "    accuracy                           1.00      5226\n",
      "   macro avg       1.00      1.00      1.00      5226\n",
      "weighted avg       1.00      1.00      1.00      5226\n",
      "\n",
      "[[3960    6]\n",
      " [   4 1256]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,prediction))\n",
    "print(confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "clf = LogisticRegression(C=10000)\n",
    "clf.fit(X_train,y_train)\n",
    "Prediction = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score of the LogisticRegression is 87.9257558362036\n",
      "[[3960    6]\n",
      " [   4 1256]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# calculate fpr & tpr for all thresholds of the classification 10-b-(iii)\\nprobs=clf.predict_proba(X_test)\\npreds=probs[:,1]\\nfpr,tpr,threshold=metrics.roc_curve(y_test,preds,pos_label='0000439')\\nroc_auc=metrics.auc(fpr,tpr)\\n\\nplt.title('Reveiver Operating Characteristic')\\nplt.plot(fpr,tpr,'b',label='AUC=%0.2f'%roc_auc)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and print the score\n",
    "Score=clf.score(X_test,y_test)\n",
    "print(\"The Score of the LogisticRegression is\",Score*100) #10-b-(i)\n",
    "#results=confusion_matrix(Xdata,XdataT) \n",
    "#print(results)\n",
    "print(confusion_matrix(y_test,prediction))# 10-b-(ii)\n",
    "\n",
    "\n",
    "# I tried finding TPR, FPR but, I have got an error like this.\n",
    "# TypeError: 'bool' object is not subscriptable\n",
    "\"\"\"\n",
    "# calculate fpr & tpr for all thresholds of the classification 10-b-(iii)\n",
    "probs=clf.predict_proba(X_test)\n",
    "preds=probs[:,1]\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,preds,pos_label='0000439')\n",
    "roc_auc=metrics.auc(fpr,tpr)\n",
    "\n",
    "plt.title('Reveiver Operating Characteristic')\n",
    "plt.plot(fpr,tpr,'b',label='AUC=%0.2f'%roc_auc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the classification for Gausian NB Model\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train,y_train)\n",
    "Prediction = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score of the Gaussian Naive Bayes classifier is 49.73210868733256\n",
      "[[3960    6]\n",
      " [   4 1256]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# calculate fpr & tpr for all thresholds of the classification 10-c-(iii)\\nprobs=clf.predict_proba(X_test)\\npreds=probs[:,1]\\nfpr,tpr,threshold=metrics.roc_curve(y_test,preds,pos_label='0000439')\\nroc_auc=metrics.auc(fpr,tpr)\\n\\nplt.title('Reveiver Operating Characteristic')\\nplt.plot(fpr,tpr,'b',label='AUC=%0.2f'%roc_auc)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and print the score\n",
    "\n",
    "Score = clf.score(X_test,y_test)\n",
    "print(\"The Score of the Gaussian Naive Bayes classifier is\", Score * 100) # 10-c-(i)\n",
    "\n",
    "print(confusion_matrix(y_test,prediction))# 10-c-(ii)\n",
    "\n",
    "# I tried finding TPR, FPR but, I have got an error like this.\n",
    "# TypeError: 'bool' object is not subscriptable\n",
    "\"\"\"\n",
    "# calculate fpr & tpr for all thresholds of the classification 10-c-(iii)\n",
    "probs=clf.predict_proba(X_test)\n",
    "preds=probs[:,1]\n",
    "fpr,tpr,threshold=metrics.roc_curve(y_test,preds,pos_label='0000439')\n",
    "roc_auc=metrics.auc(fpr,tpr)\n",
    "\n",
    "plt.title('Reveiver Operating Characteristic')\n",
    "plt.plot(fpr,tpr,'b',label='AUC=%0.2f'%roc_auc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 11\n",
    "\n",
    "\"\"\"\n",
    "I personally think that the reason \n",
    "why they(Logistic Regression, Gaussian Naive Bayes, Decision Tree) show different result. \n",
    "\n",
    "In case of, Gaussian Naive Bayes(Naive Bayes) requires me build a classification by hand.\n",
    "that means, it can work with Dataset well. but it is a discriminative model.\n",
    "\n",
    "Decision Tree and Logistic Regression, they can handle Linear Regression. \n",
    "Decision Tree cannot derive the significance of features, but Logistic Regression can.\n",
    "Decision trees can show better for categorical values than Logistic Regression.\n",
    "\n",
    "They have different characteristics and are used in different ways. so, they show different results.  \n",
    "\n",
    "- Reference\n",
    "\n",
    "\"Comparative study on Classic Machine learning Algorithms\", Medium, 2021. [Online]. \n",
    "Available: https://towardsdatascience.com/comparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
